{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976045e2-86a6-4a6f-bfdc-021acb53fcce",
   "metadata": {},
   "source": [
    "# Assignment #05\n",
    "\n",
    "Name:\n",
    "\n",
    "    Angel Manuel Perez\n",
    "\n",
    "\n",
    "# Chapter 06 (page 283): 2, 9, 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c611c274-ce2f-4c46-940b-cf3d665adaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ISLP as isl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7647a9c9-1321-4273-bc70-9b8860f5598c",
   "metadata": {},
   "source": [
    "# 6.2\n",
    "## For parts (a) through (c), indicate which of i. through iv. is correct. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8336a-923f-42fc-9380-d75b0dffe79b",
   "metadata": {},
   "source": [
    "### (a) The lasso, relative to least squares, is:\n",
    "    i. More flexible and hence will give improved prediction ac- curacy when its increase in bias is less than its decrease in variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361551e0-a278-43a1-b926-489973862e19",
   "metadata": {},
   "source": [
    "This statement is incorrect.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "+ The lasso is a regularization technique that adds a penalty term to the least squares objective function. This penalty encourages sparse solutions by shrinking some coefficients to zero. Consequently, the lasso tends to reduce the model complexity by selecting only a subset of the features, which makes it less flexible than least squares in terms of the number of features used in the model.\n",
    "\n",
    "+ When the increase in bias (due to the regularization term) is less than the decrease in variance (due to feature selection), the lasso can lead to improved prediction accuracy compared to least squares. This happens because the reduction in variance by selecting fewer features outweighs the increase in bias caused by the regularization penalty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018e8a2-491c-4bd3-a691-ca2bdefe56cb",
   "metadata": {},
   "source": [
    "    ii. More flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60921fad-25bd-43cc-aa5f-9a9585faa4cf",
   "metadata": {},
   "source": [
    "This statement is incorrect.\n",
    "\n",
    "The lasso is not more flexible than least squares. In fact, the lasso tends to produce less flexible models by shrinking coefficients towards zero and promoting sparsity in the model.\n",
    "\n",
    "The increase in variance occurs when the model becomes more flexible, i.e., it can adapt more closely to the training data. On the other hand, the decrease in bias occurs when the model becomes less flexible, which can happen with regularization techniques like the lasso.\n",
    "\n",
    "In summary, the lasso tends to decrease variance and increase bias. Therefore, for improved prediction accuracy with the lasso, you would want the increase in bias to be less than the decrease in variance. Thus, the correct choice is actually i."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45507ec7-d81f-409d-bd13-408fb8bfeef0",
   "metadata": {},
   "source": [
    "    iii. Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e5359-e8d1-4573-9b3e-3f636b5b3c5c",
   "metadata": {},
   "source": [
    "This statement is correct.\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "The lasso is indeed less flexible compared to least squares because it tends to shrink coefficients towards zero, effectively reducing the number of features used in the model. This reduction in flexibility can lead to an increase in bias.\n",
    "\n",
    "When the increase in bias (due to the regularization term) is less than the decrease in variance (due to feature selection), the lasso can lead to improved prediction accuracy compared to least squares. This is because the reduction in variance by selecting fewer features outweighs the increase in bias caused by the regularization penalty.\n",
    "\n",
    "So, the correct choice is indeed iii."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa11b3-2057-44b9-b41e-4cdb690ad0c9",
   "metadata": {},
   "source": [
    "    iv. Less flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32a894b-07b2-430c-9086-a2f10aa0eefb",
   "metadata": {},
   "source": [
    "This statement is incorrect.\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "The lasso is indeed less flexible compared to least squares because it tends to shrink coefficients towards zero, effectively reducing the number of features used in the model. This reduction in flexibility can lead to an increase in bias.\n",
    "\n",
    "However, the increase in variance occurs when the model becomes more flexible, i.e., it can adapt more closely to the training data. The decrease in bias occurs when the model becomes less flexible, which can happen with regularization techniques like the lasso.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87697ed7-5395-48e3-842b-9a653e19d072",
   "metadata": {},
   "source": [
    "**For improved prediction accuracy with the lasso, you would want the increase in bias to be less than the decrease in variance. Therefore, the correct choice is `iii.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d4392-bf98-4cd7-ad97-61f86d23180e",
   "metadata": {},
   "source": [
    "### (b) Repeat (a) for ridge regression relative to least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c62ffb-719d-48ca-a7aa-7a19a5a3bde4",
   "metadata": {},
   "source": [
    "    i. More flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368e394-0e05-41be-a6b4-458dcb22a2ab",
   "metadata": {},
   "source": [
    "This statement is incorrect for ridge regression. \n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Ridge regression, like the lasso, introduces a penalty term to the least squares objective function, but it shrinks coefficients towards zero without necessarily setting them exactly to zero as the lasso does. This tends to make the model less flexible rather than more flexible. Improved prediction accuracy generally occurs when the increase in bias is less than the decrease in variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c20273-0c8c-4184-b750-57e752c9f3b2",
   "metadata": {},
   "source": [
    "    ii. More flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e63bfa-0bf6-4346-9fd1-ab54551fa7f3",
   "metadata": {},
   "source": [
    "This statement is incorrect. \n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Ridge regression typically reduces the flexibility of the model compared to least squares by shrinking coefficients. The decrease in bias resulting from ridge regression can lead to improved prediction accuracy if it outweighs the increase in variance, not the other way around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8753f-b655-446a-8483-b2f7dc8d8b30",
   "metadata": {},
   "source": [
    "    iii. Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6124c5-ca0d-4d64-9318-91048bd91802",
   "metadata": {},
   "source": [
    "This statement is correct. \n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Ridge regression tends to make the model less flexible by shrinking coefficients towards zero, which can increase bias. However, if the decrease in variance due to the regularization term outweighs the increase in bias, prediction accuracy can improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcbba69-7c0d-43c3-bf2f-fdc962a3254f",
   "metadata": {},
   "source": [
    "    iv. Less flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07943fff-0126-485d-9f8d-510ac01bc11b",
   "metadata": {},
   "source": [
    "This statement is incorrect. \n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "It suggests that improved prediction accuracy occurs when the increase in variance is less than the decrease in bias, which is generally not true for ridge regression. Ridge regression typically reduces variance by shrinking coefficients, while potentially increasing bias due to the regularization term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ea4ec-7050-43ed-a066-7c7d64d2f1d7",
   "metadata": {},
   "source": [
    "**For improved prediction accuracy with ridge regression, you would indeed want the increase in bias to be less than the decrease in variance. This aligns with choice `iii.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7817089a-45e2-403f-9a7a-a3c0350f641d",
   "metadata": {},
   "source": [
    "### (c) Repeat (a) for non-linear methods relative to least squares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce64104-c550-4fc0-9e9b-15181dc88a70",
   "metadata": {},
   "source": [
    "    i. More flexible and hence will give improved prediction ac- curacy when its increase in bias is less than its decrease in variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1420b118-9d3f-4957-87dd-e00475690f75",
   "metadata": {},
   "source": [
    "This statement is generally correct for non-linear methods compared to least squares. \n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Non-linear methods, such as polynomial regression or kernel methods, can introduce more flexibility by allowing for non-linear relationships between features and the target variable. Improved prediction accuracy often occurs when the increase in bias (due to the model's complexity) is less than the decrease in variance (due to the model's ability to capture more intricate patterns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751520d-1420-43ee-8337-77116105836f",
   "metadata": {},
   "source": [
    "    ii. More flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ec9f9-c4d3-48da-b3d1-9a20790f0a83",
   "metadata": {},
   "source": [
    "This statement is incorrect.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Increased flexibility typically leads to higher variance in the model, not less. While non-linear methods can introduce more flexibility, this can also lead to overfitting and increased variance. Improved prediction accuracy usually occurs when the increase in bias is less than the decrease in variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e45a20-7585-46b9-b297-ec1da27ab2ce",
   "metadata": {},
   "source": [
    "    iii. Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04273a8e-bc82-4a65-acdf-f84d4b901b1b",
   "metadata": {},
   "source": [
    "This statement is incorrect for non-linear methods.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Non-linear methods tend to introduce more flexibility compared to least squares, potentially resulting in higher variance. Improved prediction accuracy generally occurs when the increase in bias is less than the decrease in variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49b3de-4149-4fbc-8146-bb37aea0cb4a",
   "metadata": {},
   "source": [
    "    iv. Less flexible and hence will give improved prediction accuracy when its increase in variance is less than its decrease in bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a40ca-ddd2-4770-945c-da04bab3a053",
   "metadata": {},
   "source": [
    "This statement is correct. \n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "Non-linear methods, by introducing more flexibility, often lead to an increase in variance. However, if the increase in bias due to model complexity is less than the decrease in variance, the prediction accuracy can improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32636161-7375-4239-bace-f401f7f93232",
   "metadata": {},
   "source": [
    "**While choice `iv.` is more appropriate and generally holds true for non-linear methods, choice `i.` could potentially be applicable in certain scenarios where the balance between bias and variance favors increased flexibility. However, in many cases, choice `iv.` tends to be more accurate and aligns better with the typical bias-variance trade-off encountered when working with non-linear methods.**\n",
    "\n",
    "**So, while choice `iv.` is more commonly applicable and aligns with the general trend, choice `i.` could still be considered in specific contexts where the increase in bias is indeed less than the decrease in variance, leading to improved prediction accuracy with increased flexibility.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23794c87-574c-4713-ac75-eb4ccf2b64f6",
   "metadata": {},
   "source": [
    "# 6.9\n",
    " In this exercise, we will predict the number of applications received using the other variables in the `College` data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4866b1-0b6a-44a9-af81-2cad9c52a87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yes</td>\n",
       "      <td>587</td>\n",
       "      <td>479</td>\n",
       "      <td>158</td>\n",
       "      <td>38</td>\n",
       "      <td>62</td>\n",
       "      <td>678</td>\n",
       "      <td>41</td>\n",
       "      <td>13500</td>\n",
       "      <td>3335</td>\n",
       "      <td>500</td>\n",
       "      <td>675</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11</td>\n",
       "      <td>9727</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yes</td>\n",
       "      <td>353</td>\n",
       "      <td>340</td>\n",
       "      <td>103</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>416</td>\n",
       "      <td>230</td>\n",
       "      <td>13290</td>\n",
       "      <td>5720</td>\n",
       "      <td>500</td>\n",
       "      <td>1500</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>11.5</td>\n",
       "      <td>26</td>\n",
       "      <td>8861</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1899</td>\n",
       "      <td>1720</td>\n",
       "      <td>489</td>\n",
       "      <td>37</td>\n",
       "      <td>68</td>\n",
       "      <td>1594</td>\n",
       "      <td>32</td>\n",
       "      <td>13868</td>\n",
       "      <td>4826</td>\n",
       "      <td>450</td>\n",
       "      <td>850</td>\n",
       "      <td>89</td>\n",
       "      <td>100</td>\n",
       "      <td>13.7</td>\n",
       "      <td>37</td>\n",
       "      <td>11487</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1038</td>\n",
       "      <td>839</td>\n",
       "      <td>227</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>973</td>\n",
       "      <td>306</td>\n",
       "      <td>15595</td>\n",
       "      <td>4400</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>11.3</td>\n",
       "      <td>23</td>\n",
       "      <td>11644</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yes</td>\n",
       "      <td>582</td>\n",
       "      <td>498</td>\n",
       "      <td>172</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>799</td>\n",
       "      <td>78</td>\n",
       "      <td>10468</td>\n",
       "      <td>3380</td>\n",
       "      <td>660</td>\n",
       "      <td>1800</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>11.5</td>\n",
       "      <td>15</td>\n",
       "      <td>8991</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Private  Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0     Yes  1660    1232     721         23         52         2885   \n",
       "1     Yes  2186    1924     512         16         29         2683   \n",
       "2     Yes  1428    1097     336         22         50         1036   \n",
       "3     Yes   417     349     137         60         89          510   \n",
       "4     Yes   193     146      55         16         44          249   \n",
       "5     Yes   587     479     158         38         62          678   \n",
       "6     Yes   353     340     103         17         45          416   \n",
       "7     Yes  1899    1720     489         37         68         1594   \n",
       "8     Yes  1038     839     227         30         63          973   \n",
       "9     Yes   582     498     172         21         44          799   \n",
       "\n",
       "   P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "2           99     11250        3750    400      1165   53        66   \n",
       "3           63     12960        5450    450       875   92        97   \n",
       "4          869      7560        4120    800      1500   76        72   \n",
       "5           41     13500        3335    500       675   67        73   \n",
       "6          230     13290        5720    500      1500   90        93   \n",
       "7           32     13868        4826    450       850   89       100   \n",
       "8          306     15595        4400    300       500   79        84   \n",
       "9           78     10468        3380    660      1800   40        41   \n",
       "\n",
       "   S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0       18.1           12    7041         60  \n",
       "1       12.2           16   10527         56  \n",
       "2       12.9           30    8735         54  \n",
       "3        7.7           37   19016         59  \n",
       "4       11.9            2   10922         15  \n",
       "5        9.4           11    9727         55  \n",
       "6       11.5           26    8861         63  \n",
       "7       13.7           37   11487         73  \n",
       "8       11.3           23   11644         80  \n",
       "9       11.5           15    8991         52  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = isl.load_data(\"College\")\n",
    "college.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d24ac6-0671-4ccd-bdbd-96aea5c94426",
   "metadata": {},
   "source": [
    "Seems that one column in the dataset contain non-numeric values, such as 'Yes', which cannot be directly used for modeling with a linear regression algorithm. Need to preprocess the data to handle these categorical variables appropriately before fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6b44e4-060c-4aa4-8088-02351c272d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F_Undergrad</th>\n",
       "      <th>P_Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room_Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S_F_Ratio</th>\n",
       "      <th>perc_alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>587</td>\n",
       "      <td>479</td>\n",
       "      <td>158</td>\n",
       "      <td>38</td>\n",
       "      <td>62</td>\n",
       "      <td>678</td>\n",
       "      <td>41</td>\n",
       "      <td>13500</td>\n",
       "      <td>3335</td>\n",
       "      <td>500</td>\n",
       "      <td>675</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11</td>\n",
       "      <td>9727</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "      <td>340</td>\n",
       "      <td>103</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>416</td>\n",
       "      <td>230</td>\n",
       "      <td>13290</td>\n",
       "      <td>5720</td>\n",
       "      <td>500</td>\n",
       "      <td>1500</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>11.5</td>\n",
       "      <td>26</td>\n",
       "      <td>8861</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1899</td>\n",
       "      <td>1720</td>\n",
       "      <td>489</td>\n",
       "      <td>37</td>\n",
       "      <td>68</td>\n",
       "      <td>1594</td>\n",
       "      <td>32</td>\n",
       "      <td>13868</td>\n",
       "      <td>4826</td>\n",
       "      <td>450</td>\n",
       "      <td>850</td>\n",
       "      <td>89</td>\n",
       "      <td>100</td>\n",
       "      <td>13.7</td>\n",
       "      <td>37</td>\n",
       "      <td>11487</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1038</td>\n",
       "      <td>839</td>\n",
       "      <td>227</td>\n",
       "      <td>30</td>\n",
       "      <td>63</td>\n",
       "      <td>973</td>\n",
       "      <td>306</td>\n",
       "      <td>15595</td>\n",
       "      <td>4400</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>11.3</td>\n",
       "      <td>23</td>\n",
       "      <td>11644</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>582</td>\n",
       "      <td>498</td>\n",
       "      <td>172</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>799</td>\n",
       "      <td>78</td>\n",
       "      <td>10468</td>\n",
       "      <td>3380</td>\n",
       "      <td>660</td>\n",
       "      <td>1800</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>11.5</td>\n",
       "      <td>15</td>\n",
       "      <td>8991</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Private  Apps  Accept  Enroll  Top10perc  Top25perc  F_Undergrad  \\\n",
       "0        1  1660    1232     721         23         52         2885   \n",
       "1        1  2186    1924     512         16         29         2683   \n",
       "2        1  1428    1097     336         22         50         1036   \n",
       "3        1   417     349     137         60         89          510   \n",
       "4        1   193     146      55         16         44          249   \n",
       "5        1   587     479     158         38         62          678   \n",
       "6        1   353     340     103         17         45          416   \n",
       "7        1  1899    1720     489         37         68         1594   \n",
       "8        1  1038     839     227         30         63          973   \n",
       "9        1   582     498     172         21         44          799   \n",
       "\n",
       "   P_Undergrad  Outstate  Room_Board  Books  Personal  PhD  Terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "2           99     11250        3750    400      1165   53        66   \n",
       "3           63     12960        5450    450       875   92        97   \n",
       "4          869      7560        4120    800      1500   76        72   \n",
       "5           41     13500        3335    500       675   67        73   \n",
       "6          230     13290        5720    500      1500   90        93   \n",
       "7           32     13868        4826    450       850   89       100   \n",
       "8          306     15595        4400    300       500   79        84   \n",
       "9           78     10468        3380    660      1800   40        41   \n",
       "\n",
       "   S_F_Ratio  perc_alumni  Expend  Grad_Rate  \n",
       "0       18.1           12    7041         60  \n",
       "1       12.2           16   10527         56  \n",
       "2       12.9           30    8735         54  \n",
       "3        7.7           37   19016         59  \n",
       "4       11.9            2   10922         15  \n",
       "5        9.4           11    9727         55  \n",
       "6       11.5           26    8861         63  \n",
       "7       13.7           37   11487         73  \n",
       "8       11.3           23   11644         80  \n",
       "9       11.5           15    8991         52  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'Private' column is in your DataFrame college_df\n",
    "college['Private'] = college['Private'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Remove fullstops from col names\n",
    "college_df = college.rename(index=str, columns={\"F.Undergrad\": \"F_Undergrad\", \n",
    "                                                   \"P.Undergrad\": \"P_Undergrad\",\n",
    "                                                   \"S.F.Ratio\": \"S_F_Ratio\",\n",
    "                                                   \"perc.alumni\": \"perc_alumni\",\n",
    "                                                   \"Grad.Rate\": \"Grad_Rate\",\n",
    "                                                   \"Room.Board\": \"Room_Board\"})\n",
    "college_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88939c44-0d55-402d-9640-5b2341f81b03",
   "metadata": {},
   "source": [
    "### (a) Split the data set into a training set and a test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7daa48d-1502-410b-8d8b-f8e0f246e3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F_Undergrad</th>\n",
       "      <th>P_Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room_Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S_F_Ratio</th>\n",
       "      <th>perc_alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1</td>\n",
       "      <td>1074</td>\n",
       "      <td>397</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>1805</td>\n",
       "      <td>433</td>\n",
       "      <td>9813</td>\n",
       "      <td>4050</td>\n",
       "      <td>425</td>\n",
       "      <td>1000</td>\n",
       "      <td>45</td>\n",
       "      <td>63</td>\n",
       "      <td>16.7</td>\n",
       "      <td>29</td>\n",
       "      <td>7307</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>1</td>\n",
       "      <td>758</td>\n",
       "      <td>428</td>\n",
       "      <td>21</td>\n",
       "      <td>46</td>\n",
       "      <td>1605</td>\n",
       "      <td>246</td>\n",
       "      <td>9858</td>\n",
       "      <td>3700</td>\n",
       "      <td>450</td>\n",
       "      <td>1200</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16</td>\n",
       "      <td>4796</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>33</td>\n",
       "      <td>71</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>8730</td>\n",
       "      <td>3600</td>\n",
       "      <td>400</td>\n",
       "      <td>800</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>9.3</td>\n",
       "      <td>17</td>\n",
       "      <td>10922</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>587</td>\n",
       "      <td>298</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>935</td>\n",
       "      <td>184</td>\n",
       "      <td>6060</td>\n",
       "      <td>3070</td>\n",
       "      <td>600</td>\n",
       "      <td>1300</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>17.7</td>\n",
       "      <td>13</td>\n",
       "      <td>5391</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>122</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>537</td>\n",
       "      <td>101</td>\n",
       "      <td>8540</td>\n",
       "      <td>3580</td>\n",
       "      <td>500</td>\n",
       "      <td>1400</td>\n",
       "      <td>61</td>\n",
       "      <td>80</td>\n",
       "      <td>8.8</td>\n",
       "      <td>32</td>\n",
       "      <td>8324</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>632</td>\n",
       "      <td>139</td>\n",
       "      <td>60</td>\n",
       "      <td>83</td>\n",
       "      <td>569</td>\n",
       "      <td>7</td>\n",
       "      <td>17238</td>\n",
       "      <td>7350</td>\n",
       "      <td>600</td>\n",
       "      <td>800</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "      <td>8.2</td>\n",
       "      <td>41</td>\n",
       "      <td>18372</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>1</td>\n",
       "      <td>1540</td>\n",
       "      <td>494</td>\n",
       "      <td>28</td>\n",
       "      <td>72</td>\n",
       "      <td>2993</td>\n",
       "      <td>347</td>\n",
       "      <td>12825</td>\n",
       "      <td>4375</td>\n",
       "      <td>500</td>\n",
       "      <td>1500</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10175</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0</td>\n",
       "      <td>2440</td>\n",
       "      <td>704</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>3006</td>\n",
       "      <td>338</td>\n",
       "      <td>5587</td>\n",
       "      <td>4845</td>\n",
       "      <td>500</td>\n",
       "      <td>600</td>\n",
       "      <td>61</td>\n",
       "      <td>63</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5733</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>1</td>\n",
       "      <td>969</td>\n",
       "      <td>226</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>1431</td>\n",
       "      <td>1522</td>\n",
       "      <td>13540</td>\n",
       "      <td>5050</td>\n",
       "      <td>630</td>\n",
       "      <td>2298</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>14.1</td>\n",
       "      <td>23</td>\n",
       "      <td>10139</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "      <td>336</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>1051</td>\n",
       "      <td>82</td>\n",
       "      <td>9400</td>\n",
       "      <td>4200</td>\n",
       "      <td>500</td>\n",
       "      <td>1600</td>\n",
       "      <td>53</td>\n",
       "      <td>58</td>\n",
       "      <td>12.5</td>\n",
       "      <td>9</td>\n",
       "      <td>7967</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Private  Accept  Enroll  Top10perc  Top25perc  F_Undergrad  P_Undergrad  \\\n",
       "360        1    1074     397         15         40         1805          433   \n",
       "336        1     758     428         21         46         1605          246   \n",
       "110        1      72      51         33         71          139            3   \n",
       "82         1     587     298         25         55          935          184   \n",
       "51         1     184     122         19         42          537          101   \n",
       "515        1     632     139         60         83          569            7   \n",
       "517        1    1540     494         28         72         2993          347   \n",
       "712        0    2440     704          2         30         3006          338   \n",
       "627        1     969     226         16         38         1431         1522   \n",
       "198        1    1107     336         12         36         1051           82   \n",
       "\n",
       "     Outstate  Room_Board  Books  Personal  PhD  Terminal  S_F_Ratio  \\\n",
       "360      9813        4050    425      1000   45        63       16.7   \n",
       "336      9858        3700    450      1200   42        45       17.6   \n",
       "110      8730        3600    400       800   92        92        9.3   \n",
       "82       6060        3070    600      1300   62        66       17.7   \n",
       "51       8540        3580    500      1400   61        80        8.8   \n",
       "515     17238        7350    600       800   95       100        8.2   \n",
       "517     12825        4375    500      1500   85        85       12.2   \n",
       "712      5587        4845    500       600   61        63       16.0   \n",
       "627     13540        5050    630      2298   66        68       14.1   \n",
       "198      9400        4200    500      1600   53        58       12.5   \n",
       "\n",
       "     perc_alumni  Expend  Grad_Rate  \n",
       "360           29    7307         78  \n",
       "336           16    4796         55  \n",
       "110           17   10922         58  \n",
       "82            13    5391         49  \n",
       "51            32    8324         56  \n",
       "515           41   18372         73  \n",
       "517           16   10175         89  \n",
       "712           11    5733         31  \n",
       "627           23   10139         47  \n",
       "198            9    7967         22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "np.random.seed(1)\n",
    "# Separate features (X) and target variable (y)\n",
    "X = college_df.drop(columns=['Apps'])  # Features (attributes) excluding the target variable 'Apps'\n",
    "y = college_df['Apps']  # Target variable 'Apps'\n",
    "\n",
    "# Split the data into training and test sets (70% training, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336878dd-1562-415c-8653-b2c2b956bcce",
   "metadata": {},
   "source": [
    "### (b) Fit a linear model using least squares on the training set, and report the test error obtained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43d96929-c318-4a40-8893-7913a02aac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error (Mean Squared Error): 1931803.1942069673\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear model using least squares on the training set\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the test error (Mean Squared Error)\n",
    "test_error = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test Error (Mean Squared Error):\", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db4487-9d52-4c73-b1ac-9d3f216efd5a",
   "metadata": {},
   "source": [
    "### (c) Fit a ridge regression model on the training set, with λ chosen by cross-validation. Report the test error obtained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752ed918-4593-4146-bf91-0fb65fb2caf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error (Mean Squared Error) for Ridge: 1931039.2927319494\n",
      "Ridge Lambda value: 1\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ridge = Ridge()\n",
    "param_grid_ridge = {'alpha': [0.1, 1, 10]}  # Adjust lambda values as needed\n",
    "grid_search_ridge = GridSearchCV(estimator=ridge, param_grid=param_grid_ridge, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "ridge_best = grid_search_ridge.best_estimator_\n",
    "ridge_best.fit(X_train, y_train)\n",
    "ridge_error = mean_squared_error(y_test, ridge_best.predict(X_test))\n",
    "print(\"Test Error (Mean Squared Error) for Ridge:\", ridge_error)\n",
    "print(\"Ridge Lambda value:\", ridge_best.alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759cd20-2e94-4c91-adc7-3e8dff4ecc2e",
   "metadata": {},
   "source": [
    "### (d) Fit a lasso model on the training set, with λ chosen by cross- validation. Report the test error obtained, along with the num- ber of non-zero coefficient estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3639e5-b8a3-40b8-b395-938bdd07d91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error (Mean Squared Error) for Lasso: 1931745.9338190495\n",
      "Lasso Lambda value: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "lasso = Lasso()\n",
    "param_grid_lasso = {'alpha': [0.1, 1, 10]}  # Adjust lambda values as needed\n",
    "grid_search_lasso = GridSearchCV(estimator=lasso, param_grid=param_grid_lasso, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "lasso_best = grid_search_lasso.best_estimator_\n",
    "lasso_best.fit(X_train, y_train)\n",
    "lasso_error = mean_squared_error(y_test, lasso_best.predict(X_test))\n",
    "print(\"Test Error (Mean Squared Error) for Lasso:\", lasso_error)\n",
    "print(\"Lasso Lambda value:\", lasso_best.alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2280b-8de7-49da-9549-d412948e236e",
   "metadata": {},
   "source": [
    "### (e) Fit a PCR model on the training set, with M chosen by cross- validation. Report the test error obtained, along with the value of M selected by cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13786cd9-9702-4b30-90f2-9b8348b7dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error (Mean Squared Error) for PCR: 1929510.984703442\n",
      "Value of M selected by cross-validation for PCR: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# PCR Regression\n",
    "pipe_pcr = Pipeline([('pca', PCA()), ('regressor', LinearRegression())])\n",
    "param_grid_pcr = {'pca__n_components': [5, 10, 15]}  # Adjust the number of components as needed\n",
    "grid_search_pcr = GridSearchCV(pipe_pcr, param_grid=param_grid_pcr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_pcr.fit(X_train, y_train)\n",
    "pcr_best = grid_search_pcr.best_estimator_\n",
    "pcr_best.fit(X_train, y_train)\n",
    "pcr_error = mean_squared_error(y_test, pcr_best.predict(X_test))\n",
    "print(\"Test Error (Mean Squared Error) for PCR:\", pcr_error)\n",
    "print(\"Value of M selected by cross-validation for PCR:\", pcr_best.named_steps['pca'].n_components_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce801a-0a29-4336-9edd-8941e5a43277",
   "metadata": {},
   "source": [
    "### (f) Fit a PLS model on the training set, with M chosen by cross-validation. Report the test error obtained, along with the value of M selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6660f9-21d4-4bb0-a75d-2d87fbce4d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error (Mean Squared Error) for PLS: 1931741.7620230694\n",
      "Value of M selected by cross-validation for PLS: 15\n"
     ]
    }
   ],
   "source": [
    "# PLS Regression\n",
    "param_grid_pls = {'n_components': [5, 10, 15]}  # Adjust the number of components as needed\n",
    "grid_search_pls = GridSearchCV(PLSRegression(), param_grid=param_grid_pls, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_pls.fit(X_train, y_train)\n",
    "pls_best = grid_search_pls.best_estimator_\n",
    "pls_best.fit(X_train, y_train)\n",
    "pls_error = mean_squared_error(y_test, pls_best.predict(X_test))\n",
    "print(\"Test Error (Mean Squared Error) for PLS:\", pls_error)\n",
    "print(\"Value of M selected by cross-validation for PLS:\", pls_best.n_components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da91c17-c528-458d-bdca-5d2b6279ddff",
   "metadata": {},
   "source": [
    "### (g) Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much difference among the test errors resulting from these five approaches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cca9a45-f859-4425-aad2-08c78b388923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Error (Mean Squared Error)</th>\n",
       "      <th>Hyperparameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>1.931803e+06</td>\n",
       "      <td>[No Hyperparameter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.931039e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.931746e+06</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>1.929511e+06</td>\n",
       "      <td>(PCA(n_components=15), LinearRegression())</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>1.931742e+06</td>\n",
       "      <td>PLSRegression(n_components=15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Test Error (Mean Squared Error)  \\\n",
       "Linear                     1.931803e+06   \n",
       "Ridge                      1.931039e+06   \n",
       "Lasso                      1.931746e+06   \n",
       "PCR                        1.929511e+06   \n",
       "PLS                        1.931742e+06   \n",
       "\n",
       "                                    Hyperparameter  \n",
       "Linear                         [No Hyperparameter]  \n",
       "Ridge                                            1  \n",
       "Lasso                                          0.1  \n",
       "PCR     (PCA(n_components=15), LinearRegression())  \n",
       "PLS                 PLSRegression(n_components=15)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Actual test errors obtained from each test\n",
    "test_errors = {\n",
    "    'Linear': test_error,  # Actual test error obtained from linear regression\n",
    "    'Ridge': ridge_error,  # Actual test error obtained from Ridge regression\n",
    "    'Lasso': lasso_error,  # Actual test error obtained from Lasso regression\n",
    "    'PCR': pcr_error,  # Actual test error obtained from PCR\n",
    "    'PLS': pls_error  # Actual test error obtained from PLS\n",
    "}\n",
    "\n",
    "# Actual hyperparameters obtained from each test\n",
    "hyperparameters = {\n",
    "    'Linear': '[No Hyperparameter]',  # No hyperparameter for linear regression\n",
    "    'Ridge': ridge_best.alpha,  # Actual value of lambda selected by cross-validation for Ridge regression\n",
    "    'Lasso': lasso_best.alpha,  # Actual value of lambda selected by cross-validation for Lasso regression\n",
    "    'PCR': pcr_best,  # Actual value of M selected by cross-validation for PCR\n",
    "    'PLS': pls_best  # Actual value of M selected by cross-validation for PLS\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "results_df = pd.DataFrame({'Test Error (Mean Squared Error)': test_errors, 'Hyperparameter': hyperparameters})\n",
    "\n",
    "# Print the DataFrame\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055bb149-9d37-4501-8cb7-8ddba1c5d7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001.6383526383524"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_Mean = college_df['Apps'].mean()\n",
    "app_Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f31a1c39-2579-4b7f-a165-73402ae97587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Error (Mean Squared Error): 1931168.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the test errors\n",
    "test_errors = np.array([1.931803e+06, 1.931039e+06, 1.931746e+06, 1.929511e+06, 1.931742e+06])\n",
    "\n",
    "# Calculate the average of the test errors\n",
    "average_test_error = np.mean(test_errors)\n",
    "\n",
    "# Display the average test error\n",
    "print(\"Average Test Error (Mean Squared Error):\", average_test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dea11f1d-6e97-48a5-b263-f3474a2c603d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1928166.5616473616"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_Mean - average_test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa34eb-8656-4877-97a9-439a7a9ace80",
   "metadata": {},
   "source": [
    "# 6.11\n",
    "## We will now try to predict per capita crime rate in the Boston data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03418bf-6854-4948-8c3a-fe8d4dac89ea",
   "metadata": {},
   "source": [
    "### (a) Try out some of the regression methods explored in this chapter, such as best subset selection, the lasso, ridge regression, and PCR. Present and discuss results for the approaches that you consider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d56220e-1e83-43fe-af7b-65acd0e03494",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6969b89c-cf55-4597-bc4b-872aa847d768",
   "metadata": {},
   "source": [
    "### (b) Propose a model (or set of models) that seem to perform well on this data set, and justify your answer. Make sure that you are evaluating model performance using validation set error, cross- validation, or some other reasonable alternative, as opposed to using training error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d787cd44-ddb2-4742-abd1-6a9ef75898f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a4a96ea-d6bd-4f7a-8a78-20ac8a45157b",
   "metadata": {},
   "source": [
    "### (c) Does your chosen model involve all of the features in the data set? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de61d0-b25a-43f9-920f-9d0a5fe16f4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5961e8a-fe64-4ebe-9d5b-6a5c9695cb6e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
